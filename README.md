# Data Pipeline: CSV Ingestion & DeltaLake Processing with ADF & Databricks

## ðŸ“– Project Overview
This project demonstrates an **end-to-end data pipeline** for processing **CSV files** using **Azure Data Factory (ADF)** and **Databricks**. The pipeline consists of:
1. **Ingesting CSV files** from a **raw bucket**.
2. **Processing and converting CSV to Parquet** using **Azure Data Factory (ADF)** and dispatching files to a landing bucket in the deltalake.
3. **Triggering a Databricks workflow** based on file arrival.
4. **Processing data using Delta Lake and Change Data Feed (CDF)** for efficient data modeling.
##

![image](https://github.com/user-attachments/assets/a980d24d-72b3-46e8-92a8-3b83f12e5348)
